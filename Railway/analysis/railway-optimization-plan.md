# Railway: коррекция анализа и план имплементации

Дата: 11 Feb 2026 (Europe/Kyiv)

## 1) Оценка исходного анализа

Исходный анализ в целом корректный: предложены верные рычаги снижения стоимости (декомпозиция сервисов, лимиты, управление очередями, оптимизация Docker, мониторинг). Ниже — важные корректировки, чтобы избежать ложной экономии и деградации SLA.

### Что подтверждаем

- Разделение API / bot / worker по отдельным Railway сервисам — ключевая мера против конкуренции за CPU/RAM.
- Снижение BullMQ concurrency и чистка завершённых задач — быстрое уменьшение давления на Redis и память.
- Наблюдаемое, пошаговое снижение ресурсов — правильная стратегия.

### Что корректируем

1. **Начальные лимиты ресурсов**
   - Не начинать «1 GB + 1 vCPU для каждого сервиса» как универсальный baseline.
   - Рекомендованный старт после профилирования:
     - API: 0.5 vCPU / 512 MB
     - Bot: 0.25–0.5 vCPU / 256–384 MB
     - Worker: 0.5–1 vCPU / 512 MB–1 GB
   - Повышать только при подтверждённых saturation-событиях (CPU > 80% sustained, memory > 85%, latency/SLA деградация).

2. **Ограничение heap через `--max-old-space-size`**
   - Применять только после фикса фактического resident set и GC-пауз.
   - Слишком низкий heap для API может увеличить GC overhead и latency.
   - Стартовые ориентиры:
     - API: 384–512
     - Bot: 192–256
     - Worker: 512–768 (зависит от типа jobs)

3. **PM2 `max_memory_restart`**
   - Это защитный механизм, но не основная оптимизация.
   - Частые рестарты маскируют утечки и создают «пилу» latency.
   - Нужно дополнительно ввести алерт: >3 рестарта за 15 минут = инцидент.

4. **`instances: 'max'`**
   - Нельзя фиксировать правило «1–2 инстанса всегда».
   - Для I/O API — часто достаточно 1 инстанса, но при bursts/long polling может требоваться 2.
   - Решение принимать по p95 latency + queue depth + CPU steal.

5. **Frontend на CDN**
   - Выносить только если web действительно статический (SPA без server runtime).
   - Если есть SSR/динамические server routes — оставить в Railway или переносить на платформу с SSR.

6. **Redis eviction policy**
   - `volatile-lru` подходит только если TTL выставлен почти для всех ключей.
   - Если в Redis есть персистентно важные ключи — лучше `allkeys-lru` + namespace/TTL стратегия.

7. **Autoscaling как источник экономии**
   - Автоскейл снижает риск деградации, но не всегда снижает счёт.
   - Для cost-контроля нужен schedule-based scaling + лимиты на max replicas.

---

## 2) Приоритизированный план имплементации (подзадачи)

### Этап A — Базовая измеримость (обязательно перед изменениями)

**A1. Метрики по сервисам (7–14 дней):**
- Зафиксировать по каждому процессу: CPU avg/p95, RSS avg/p95, restarts, uptime, p95 latency API, Redis memory.
- Выгрузить baseline в `Railway/analysis/baseline-YYYY-MM-DD.md`.

**A2. Карта тяжёлых операций:**
- Сопоставить пики с типами задач (BullMQ job name, endpoint, cron).
- Сформировать топ-5 «дорогих» сценариев и долю в общей нагрузке.

**A3. SLO/SLA рамки:**
- Зафиксировать допустимые пороги: API p95, error rate, max queue lag.
- Без этого нельзя валидно «удешевлять» инфраструктуру.

### Этап B — Разделение рантаймов

**B1. Декомпозиция процессов:**
- Развернуть отдельные Railway сервисы: `api`, `bot`, `worker`.
- Проверить, что каждый сервис запускает только свой entrypoint.

**B2. Разделение переменных окружения:**
- Сформировать матрицу env per service (минимально необходимые секреты).
- Исключить «общий .env на всё».

**B3. Healthchecks и restart policy:**
- Проверить liveness/readiness для каждого сервиса.
- Ограничить restart bursts (алерты на частые рестарты).

### Этап C — Управление памятью/CPU

**C1. Параметры Node runtime:**
- Ввести `NODE_OPTIONS=--max-old-space-size=<value>` отдельно для api/bot/worker.
- Значения подобрать по данным baseline, не «вслепую».

**C2. PM2/процессы:**
- Если PM2 остаётся: задать `max_memory_restart`, `min_uptime`, `max_restarts`.
- Проверить целесообразность single-process без PM2 для части сервисов.

**C3. Тонкая настройка replicas/instances:**
- Начать с 1 инстанса на сервис.
- Поднимать до 2+ только при подтверждённом росте latency/queue lag.

### Этап D — Оптимизация очередей (BullMQ)

**D1. Concurrency tuning:**
- Понизить `QUEUE_CONCURRENCY` (старт: 1–2).
- Проверить throughput и queue lag под типовой нагрузкой.

**D2. Retention policy jobs:**
- Настроить `removeOnComplete` и `removeOnFail` (с лимитами/age), чтобы не терять нужную диагностику.

**D3. Перенос тяжёлых задач:**
- Для топ-2 самых тяжёлых jobs подготовить отдельный worker class/queue.
- Изолировать heavy jobs от latency-sensitive очередей.

### Этап E — Docker и build footprint

**E1. Multi-stage сборка:**
- Builder stage + runtime stage, только production dependencies.

**E2. Размер образа и cold start:**
- Зафиксировать метрику: image size до/после, время старта контейнера.

**E3. Runtime hygiene:**
- Удалить лишние кэши в образе, проверить отсутствие dev-инструментов в runtime.

### Этап F — Данные и кэш

**F1. MongoDB hygiene:**
- Проверка неиспользуемых индексов, TTL для устаревающих данных, контроль document bloat.

**F2. Redis governance:**
- Подтвердить TTL coverage, выбрать eviction policy по фактическому профилю ключей.

**F3. Большие файлы:**
- Убедиться, что бинарные артефакты вынесены в S3-compatible storage.

### Этап G — Валидация и rollout

**G1. Staging прогон:**
- Интеграционные тесты + smoke load test (фиксированный сценарий).

**G2. Canary в production:**
- Включать изменения поэтапно (worker → bot → api).
- После каждого шага оценивать 24 часа: cost, p95, errors.

**G3. Финальный отчёт:**
- Сравнение baseline vs после изменений:
  - стоимость/день,
  - p95 API,
  - queue lag,
  - memory headroom,
  - restart rate.

---

## 3) Технический backlog (конкретные задачи)

1. Подготовить `railway.json`/service config для раздельного деплоя `api|bot|worker`.
2. Разнести start-команды по сервисам (без совместного запуска процессов в одном контейнере).
3. Вынести runtime-параметры (`NODE_OPTIONS`, queue concurrency, PM2 limits) в env-переменные.
4. Внести BullMQ retention policy (`removeOnComplete/removeOnFail`) с безопасными лимитами.
5. Добавить lightweight telemetry по jobs: duration, fail reason, queue lag.
6. Оптимизировать Dockerfile в multi-stage и замерить размер/старт.
7. Обновить runbook: как откатывать лимиты и как реагировать на OOM/restart bursts.

---

## 4) Риски и меры

- **Риск:** слишком агрессивное снижение памяти → рост latency/OOM.
  - **Мера:** снижать лимиты шагами 10–20% раз в 24 часа с мониторингом.

- **Риск:** потеря диагностических данных из-за агрессивной очистки BullMQ.
  - **Мера:** хранить ограниченное окно failed jobs (count/age), метрики отправлять отдельно.

- **Риск:** разделение сервисов усложнит конфигурацию секретов.
  - **Мера:** матрица env + чек-лист обязательных переменных per service.

---

## 5) Критерии готовности (DoD для оптимизации Railway)

- Стоимость инфраструктуры снижена минимум на 15% без ухудшения SLO.
- API p95 не хуже baseline более чем на 10%.
- Queue lag в допустимых рамках, нет систематических OOM.
- Restart burst отсутствует (не более 3 рестартов/15 мин на сервис).
- Все изменения документированы в runbook и воспроизводимы из репозитория.

## 6) Статус внедрения

- Практический трекер подзадач ведётся в `docs/railway_task_board.md`.
- На текущем шаге завершён этап T1: выделены отдельные команды запуска для API, bot и worker через `Procfile.railway`.

